# 카프카 기본 개념 정리

## 1. 카프카란?

Apache Kafka는 분산 스트리밍 플랫폼으로, 대용량 실시간 데이터 파이프라인과 스트리밍 애플리케이션을 구축하기 위해 사용된다. LinkedIn에서 개발했으며, 현재는 Apache Software Foundation에서 관리하는 오픈소스 프로젝트다.

## 2. 핵심 개념

### 2.1 Producer (생산자)

- 메시지를 생성하여 Kafka 토픽으로 전송하는 애플리케이션
- 메시지를 어느 파티션에 보낼지 결정 (키 기반(Hash를 사용) 또는 라운드로빈)
- Spring Kafka에서는 `KafkaTemplate`을 사용하여 구현

```java
kafkaTemplate.send(topic, key, message);
```

### 2.2 Consumer (소비자)

- Kafka 토픽에서 메시지를 읽어오는 애플리케이션
- Consumer Group에 속하여 메시지를 분산 처리
- Spring Kafka에서는 `@KafkaListener` 어노테이션 사용

```java
@KafkaListener(topics = "order-created", groupId = "order-group")
public void consume(OrderEvent event) {
    // 메시지 처리
}
```

### 2.3 Topic (토픽)

- 메시지가 저장되는 논리적 카테고리
- 데이터베이스의 테이블과 유사한 개념
- 여러 파티션으로 나뉘어 분산 저장

### 2.4 Partition (파티션)

- 토픽을 물리적으로 분할한 단위
- 순서 보장: 같은 파티션 내에서는 메시지 순서가 보장됨
- 병렬 처리: 파티션 수만큼 Consumer를 배치하여 처리량 향상
- 파티션은 불변 로그 구조로 메시지가 순차적으로 추가됨

### 2.5 Offset (오프셋)

- 파티션 내 메시지의 위치를 나타내는 고유 번호
- Consumer가 어디까지 읽었는지 추적하는 데 사용
- 자동 커밋 vs 수동 커밋
  - 자동 커밋: 일정 간격마다 자동으로 오프셋 저장
  - 수동 커밋: 메시지 처리 완료 후 명시적으로 `ack.acknowledge()` 호출

### 2.6 Consumer Group (컨슈머 그룹)

- 하나의 토픽을 여러 Consumer가 협력하여 처리하는 단위
- 같은 그룹 내 Consumer들은 파티션을 분배받아 처리
- 다른 그룹의 Consumer는 독립적으로 동일 메시지 수신 가능
- 예: `groupId = "order-group"`

### 2.7 Broker (브로커)

- Kafka 서버를 구성하는 개별 노드
- 메시지 저장, 파티션 관리, Producer/Consumer 요청 처리
- 여러 Broker가 클러스터를 구성하여 고가용성 제공

### 2.8 Replication (복제)

- 데이터 손실 방지를 위해 파티션을 여러 Broker에 복제
- Replication Factor: 복제본 개수 (1이면 복제 없음)
- Leader/Follower 구조: 하나의 Leader가 읽기/쓰기 담당, Follower는 복제본 유지

## 3. Kafka 동작 원리

### 3.1 메시지 전송 흐름

```
Producer → Topic (Partition 0, 1, 2...) → Consumer Group
```

1. Producer가 메시지를 토픽으로 전송
2. 메시지는 파티션에 순차적으로 저장 (오프셋 부여)
3. Consumer Group의 각 Consumer가 파티션을 할당받아 메시지 읽기
4. 처리 완료 후 오프셋 커밋

### 3.2 순서 보장

- 동일 파티션 내에서만 순서 보장
- 키가 같은 메시지는 같은 파티션으로 전송됨
- 전체 토픽 순서 보장이 필요하면 파티션을 1개로 설정 (처리량 감소)

### 3.3 At-Least-Once vs At-Most-Once

- **At-Least-Once**: 메시지가 최소 한 번은 처리됨 (중복 가능)
  - 수동 커밋 사용 시 달성
- **At-Most-Once**: 메시지가 최대 한 번만 처리됨 (손실 가능)
  - 자동 커밋 사용 시 발생 가능
- **Exactly-Once**: 정확히 한 번만 처리 (고급 기능, 트랜잭션 필요)

## 4. KRaft 모드 vs Zookeeper 모드

### 4.1 Zookeeper 모드 (기존 방식)

- Kafka 클러스터 메타데이터 관리를 위해 Zookeeper 필요
- Broker 리더 선출, 설정 관리 등을 Zookeeper가 담당
- 운영 복잡도 증가 (Kafka + Zookeeper 모두 관리 필요)

### 4.2 KRaft 모드 (최신 방식, Kafka 2.8+)

- Kafka 자체적으로 메타데이터 관리 (Zookeeper 제거)
- Raft 프로토콜 기반 합의 알고리즘 사용
- 운영 단순화, 성능 향상
- Kafka 3.x 버전부터 프로덕션 레디

**KRaft 모드 설정 예시 (docker-compose.yml):**

```yaml
KAFKA_PROCESS_ROLES: broker,controller
KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093
```

## 5. 실무 활용 시나리오

### 5.1 이벤트 기반 아키텍처

- 마이크로서비스 간 비동기 통신
- 주문 생성 → Kafka → 재고 차감, 알림 발송 등

### 5.2 로그 수집 및 모니터링

- 애플리케이션 로그를 Kafka로 수집
- ELK 스택과 연동하여 중앙 집중식 로그 분석

### 5.3 데이터 파이프라인

- CDC (Change Data Capture)를 통한 DB 변경 이벤트 스트리밍
- Kafka Connect를 이용한 외부 시스템 연동

### 5.4 CQRS 패턴

- Command와 Query 모델 분리
- 쓰기 모델의 변경 이벤트를 Kafka로 발행하여 읽기 모델 업데이트

## 6. Spring Kafka 주요 설정

### 6.1 Producer 설정

```properties
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.springframework.kafka.support.serializer.JsonSerializer
spring.kafka.producer.acks=all  # 모든 복제본에 쓰기 완료 확인
spring.kafka.producer.retries=3  # 실패 시 재시도 횟수
```

### 6.2 Consumer 설정

```properties
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.springframework.kafka.support.serializer.JsonDeserializer
spring.kafka.consumer.auto-offset-reset=earliest  # 최초 오프셋이 없을 때 처음부터 읽기
spring.kafka.consumer.enable-auto-commit=false  # 수동 커밋 사용
spring.kafka.listener.ack-mode=manual  # 수동 ack 모드
```

### 6.3 JSON 직렬화 설정

```properties
spring.kafka.consumer.properties.spring.json.trusted.packages=*  # 모든 패키지 신뢰
```

## 7. 주의사항 및 활용 팁

### 7.1 메시지 크기

- Kafka는 기본적으로 1MB 메시지 크기 제한
- 큰 메시지는 외부 저장소 저장 후 참조 전송 권장

### 7.2 컨슈머 처리 시간

- 긴 처리 시간은 리밸런싱 발생 가능
- `max.poll.interval.ms` 설정 조정 필요

### 7.3 예외 처리

- Consumer에서 예외 발생 시 오프셋 커밋 전략 중요
- Dead Letter Queue (DLQ) 패턴 고려

### 7.4 멱등성 보장

- Producer 재시도로 인한 중복 메시지 방지
- `enable.idempotence=true` 설정 권장

### 7.5 파티션 수 설계

- 초기에 충분한 파티션 확보 (나중에 늘리기 어려움)
- Consumer 수와 동일하거나 배수로 설정하여 병렬 처리 극대화

## 8. 모니터링 지표

- **Lag**: Consumer가 처리하지 못한 메시지 수
- **Throughput**: 초당 처리 메시지 수
- **Error Rate**: 처리 실패율
- **Replication Status**: 복제 상태 확인

## 9. 참고 자료

- Apache Kafka 공식 문서: https://kafka.apache.org/documentation/
- Spring for Apache Kafka: https://spring.io/projects/spring-kafka
- Confluent Platform: https://docs.confluent.io/
